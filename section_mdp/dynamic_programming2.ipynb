{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from puddle_world import *\n",
    "import itertools \n",
    "import collections \n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicProgramming: \n",
    "    def __init__(self, widths, goal, puddles, time_interval, sampling_num, \\\n",
    "                 puddle_coef=100.0, lowerleft=np.array([-4, -4]).T, upperright=np.array([4, 4]).T): \n",
    "        self.pose_min = np.r_[lowerleft, 0]\n",
    "        self.pose_max = np.r_[upperright, math.pi*2]\n",
    "        self.widths = widths\n",
    "        self.goal = goal\n",
    "        \n",
    "        self.index_nums = ((self.pose_max - self.pose_min)/self.widths).astype(int)\n",
    "        nx, ny, nt = self.index_nums\n",
    "        self.indexes = list(itertools.product(range(nx), range(ny), range(nt)))\n",
    "        \n",
    "        self.value_function, self.final_state_flags =  self.init_value_function() \n",
    "        self.policy = self.init_policy()\n",
    "        self.actions = list(set([tuple(self.policy[i]) for i in self.indexes]))\n",
    "        \n",
    "        self.state_transition_probs = self.init_state_transition_probs(time_interval, sampling_num)\n",
    "        self.depths = self.depth_means(puddles, sampling_num)\n",
    "        \n",
    "        self.time_interval = time_interval\n",
    "        self.puddle_coef = puddle_coef\n",
    "        \n",
    "    def value_iteration_sweep(self): #追加\n",
    "        max_delta = 0.0\n",
    "        for index in self.indexes:\n",
    "            if not self.final_state_flags[index]:\n",
    "                max_q = -1e100\n",
    "                max_a = None\n",
    "                qs = [self.action_value(a, index) for a in self.actions] #全行動の行動価値を計算\n",
    "                max_q = max(qs)                               #最大の行動価値\n",
    "                max_a = self.actions[np.argmax(qs)]   #最大の行動価値を与える行動\n",
    "                \n",
    "                delta = abs(self.value_function[index] - max_q)            #変化量\n",
    "                max_delta = delta if delta > max_delta else max_delta #スイープ中で最大の変化量の更新\n",
    "                \n",
    "                self.value_function[index] = max_q      #価値の更新\n",
    "                self.policy[index] = np.array(max_a).T  #方策の更新\n",
    "            \n",
    "        return max_delta        \n",
    "        \n",
    "    def policy_evaluation_sweep(self):   \n",
    "        max_delta = 0.0\n",
    "        for index in self.indexes:\n",
    "            if not self.final_state_flags[index]:\n",
    "                q = self.action_value(tuple(self.policy[index]), index)\n",
    "                \n",
    "                delta = abs(self.value_function[index] - q)\n",
    "                max_delta = delta if delta > max_delta else max_delta\n",
    "                \n",
    "                self.value_function[index] = q\n",
    "            \n",
    "        return max_delta\n",
    "    \n",
    "    def action_value(self, action, index): #はみ出しペナルティー追加\n",
    "        value = 0.0\n",
    "        for delta, prob in self.state_transition_probs[(action, index[2])]: \n",
    "            after, edge_reward = self.edge_correction(np.array(index).T + delta)\n",
    "            after = tuple(after)\n",
    "            reward = - self.time_interval * self.depths[(after[0], after[1])] * self.puddle_coef - self.time_interval + edge_reward\n",
    "            value += (self.value_function[after] + reward) * prob\n",
    "\n",
    "        return value\n",
    "            \n",
    "    def edge_correction(self, index): #変更\n",
    "        edge_reward = 0.0\n",
    "        index[2] = (index[2] + self.index_nums[2])%self.index_nums[2] #方角の処理\n",
    "        \n",
    "        for i in range(2):\n",
    "            if index[i] < 0:\n",
    "                index[i] = 0\n",
    "                edge_reward = -1e100\n",
    "            elif index[i] >= self.index_nums[i]:\n",
    "                index[i] = self.index_nums[i]-1\n",
    "                edge_reward = -1e100\n",
    "                \n",
    "        return index, edge_reward\n",
    "        \n",
    "    def depth_means(self, puddles, sampling_num):\n",
    "        ###セルの中の座標を均等にsampling_num**2点サンプリング###\n",
    "        dx = np.linspace(0, self.widths[0], sampling_num) \n",
    "        dy = np.linspace(0, self.widths[1], sampling_num)\n",
    "        samples = list(itertools.product(dx, dy))\n",
    "        \n",
    "        tmp = np.zeros(self.index_nums[0:2]) #深さの合計が計算されて入る\n",
    "        for xy in itertools.product(range(self.index_nums[0]), range(self.index_nums[1])):\n",
    "            for s in samples:\n",
    "                pose = self.pose_min + self.widths*np.array([xy[0], xy[1], 0]).T + np.array([s[0], s[1], 0]).T #セルの中心の座標\n",
    "                for p in puddles:\n",
    "                    tmp[xy] += p.depth*p.inside(pose) #深さに水たまりの中か否か（1 or 0）をかけて足す\n",
    "                        \n",
    "            tmp[xy] /= sampling_num**2 #深さの合計から平均値に変換\n",
    "                       \n",
    "        return tmp\n",
    "    \n",
    "    def init_state_transition_probs(self, time_interval, sampling_num):\n",
    "        ###セルの中の座標を均等にsampling_num**3点サンプリング###\n",
    "        dx = np.linspace(0.001, self.widths[0]*0.999, sampling_num) #隣のセルにはみ出さないように端を避ける\n",
    "        dy = np.linspace(0.001, self.widths[1]*0.999, sampling_num)\n",
    "        dt = np.linspace(0.001, self.widths[2]*0.999, sampling_num)\n",
    "        samples = list(itertools.product(dx, dy, dt))\n",
    "        \n",
    "        ###各行動、各方角でサンプリングした点を移動してインデックスの増分を記録###\n",
    "        tmp = {}\n",
    "        for a in self.actions:\n",
    "            for i_t in range(self.index_nums[2]):\n",
    "                transitions = []\n",
    "                for s in samples:\n",
    "                    before = np.array([s[0], s[1], s[2] + i_t*self.widths[2]]).T + self.pose_min  #遷移前の姿勢\n",
    "                    before_index = np.array([0, 0, i_t]).T                                                      #遷移前のインデックス\n",
    "                \n",
    "                    after = IdealRobot.state_transition(a[0], a[1], time_interval, before)   #遷移後の姿勢\n",
    "                    after_index = np.floor((after - self.pose_min)/self.widths).astype(int)   #遷移後のインデックス\n",
    "                    \n",
    "                    transitions.append(after_index - before_index)                                  #インデックスの差分を追加\n",
    "                    \n",
    "                unique, count = np.unique(transitions, axis=0, return_counts=True)   #集計（どのセルへの遷移が何回か）\n",
    "                probs = [c/sampling_num**3 for c in count]                   #サンプル数で割って確率にする\n",
    "                tmp[a,i_t] = list(zip(unique, probs))\n",
    "                \n",
    "        return tmp\n",
    "        \n",
    "    def init_policy(self):\n",
    "        tmp = np.zeros(np.r_[self.index_nums,2]) #制御出力が2次元なので、配列の次元を4次元に\n",
    "        for index in self.indexes:\n",
    "            center = self.pose_min + self.widths*(np.array(index).T + 0.5)  #セルの中心の座標\n",
    "            tmp[index] = PuddleIgnoreAgent.policy(center, self.goal)\n",
    "            \n",
    "        return tmp\n",
    "        \n",
    "    def init_value_function(self): \n",
    "        v = np.empty(self.index_nums) #全離散状態を要素に持つ配列を作成\n",
    "        f = np.zeros(self.index_nums) \n",
    "        \n",
    "        for index in self.indexes:\n",
    "            f[index] = self.final_state(np.array(index).T)\n",
    "            v[index] = self.goal.value if f[index] else -100.0\n",
    "                \n",
    "        return v, f\n",
    "        \n",
    "    def final_state(self, index):\n",
    "        x_min, y_min, _ = self.pose_min + self.widths*index          #xy平面で左下の座標\n",
    "        x_max, y_max, _ = self.pose_min + self.widths*(index + 1) #右上の座標（斜め上の離散状態の左下の座標）\n",
    "        \n",
    "        corners = [[x_min, y_min, _], [x_min, y_max, _], [x_max, y_min, _], [x_max, y_max, _] ] #4隅の座標\n",
    "        return all([self.goal.inside(np.array(c).T) for c in corners ])\n",
    "    \n",
    "    def write_policy(self): ###dp2writepolicy\n",
    "        with open(\"policy.txt\", \"w\") as f:\n",
    "            for index in self.indexes:\n",
    "                p = self.policy[index]\n",
    "                f.write(\"{} {} {} {} {}\\n\".format(index[0], index[1], index[2], p[0], p[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns   ###dp2exec\n",
    "\n",
    "puddles = [Puddle((-2, 0), (0, 2), 0.1), Puddle((-0.5, -2), (2.5, 1), 0.1)] \n",
    "\n",
    "dp = DynamicProgramming(np.array([0.2, 0.2, math.pi/18]).T, Goal(-3,-3), puddles, 0.1, 10) \n",
    "\n",
    "counter = 0 #スイープの回数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 54.1262\n",
      "2 52.5407411682\n",
      "3 27.0917338198\n",
      "4 24.3970915987\n",
      "5 19.9586511893\n",
      "6 18.6507747728\n",
      "7 16.2251659854\n",
      "8 15.7819528965\n",
      "9 14.1418428981\n",
      "10 13.2707312559\n",
      "11 12.4973933574\n",
      "12 11.7326677327\n",
      "13 11.2382314232\n",
      "14 10.0042235085\n",
      "15 9.1561902807\n",
      "16 8.71390741306\n",
      "17 8.31172909017\n",
      "18 8.00386716132\n",
      "19 7.67072750982\n",
      "20 7.38691533604\n",
      "21 7.13728978863\n",
      "22 6.9181356967\n",
      "23 6.8608402703\n",
      "24 6.71075053461\n",
      "25 6.55310883437\n",
      "26 6.49657837155\n",
      "27 6.17985207302\n",
      "28 6.10790245886\n",
      "29 5.84094234952\n",
      "30 5.70270593056\n",
      "31 5.5939342836\n",
      "32 5.45512894904\n",
      "33 5.33217744243\n",
      "34 5.23589819333\n",
      "35 5.14536257898\n",
      "36 5.05935991997\n",
      "37 4.97744517919\n",
      "38 4.90019546699\n",
      "39 4.82739274951\n",
      "40 4.68475075956\n",
      "41 4.479900777\n",
      "42 4.22396428024\n",
      "43 3.94097670207\n",
      "44 3.83741742273\n",
      "45 3.73333582349\n",
      "46 3.57361190958\n",
      "47 3.37037881919\n",
      "48 3.16523104736\n",
      "49 2.99729000954\n",
      "50 2.83449894646\n",
      "51 2.67931414892\n",
      "52 2.51886149326\n",
      "53 2.38170431473\n",
      "54 2.24864580448\n",
      "55 2.15865283892\n",
      "56 2.07589040639\n",
      "57 1.99291181893\n",
      "58 1.9221712944\n",
      "59 1.86045774301\n",
      "60 1.79718626961\n",
      "61 1.73018761712\n",
      "62 1.67232113214\n",
      "63 1.64668947277\n",
      "64 1.56441427834\n",
      "65 1.47029614809\n",
      "66 1.37332750051\n",
      "67 1.27528702186\n",
      "68 1.17757992258\n",
      "69 1.08402137386\n",
      "70 1.02895349997\n",
      "71 0.975366509217\n",
      "72 0.959667302248\n",
      "73 0.905477862619\n",
      "74 0.887121998352\n",
      "75 0.875538898091\n",
      "76 0.838998240454\n",
      "77 0.795569819594\n",
      "78 0.780923781309\n",
      "79 0.742647597502\n",
      "80 0.702977022581\n",
      "81 0.664111338082\n",
      "82 0.652962419495\n",
      "83 0.610866405315\n",
      "84 0.572156268715\n",
      "85 0.547993002841\n",
      "86 0.544479529517\n",
      "87 0.521700305203\n",
      "88 0.494554686303\n",
      "89 0.465319664346\n",
      "90 0.460251979657\n",
      "91 0.42954640872\n",
      "92 0.397994398752\n",
      "93 0.365994122049\n",
      "94 0.333998000435\n",
      "95 0.304630433216\n",
      "96 0.290947739094\n",
      "97 0.270047047627\n",
      "98 0.246581652566\n",
      "99 0.221223462286\n",
      "100 0.201494079478\n",
      "101 0.192183516844\n",
      "102 0.168739117384\n",
      "103 0.147084227881\n",
      "104 0.127367267333\n",
      "105 0.109609023798\n",
      "106 0.0947110627808\n",
      "107 0.0824790639427\n",
      "108 0.0713839240834\n",
      "109 0.0614176898774\n",
      "110 0.0553192937319\n",
      "111 0.0465530632375\n",
      "112 0.038955393511\n",
      "113 0.0324142779238\n",
      "114 0.0268202756182\n",
      "115 0.0222900052442\n",
      "116 0.0188158742003\n",
      "117 0.0157143985953\n",
      "118 0.0129814784504\n",
      "119 0.0106108432852\n",
      "120 0.00858752223042\n"
     ]
    }
   ],
   "source": [
    "delta = 1e100\n",
    "\n",
    "while delta > 0.01: \n",
    "    delta = dp.value_iteration_sweep()\n",
    "    counter += 1\n",
    "    print(counter, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.write_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
